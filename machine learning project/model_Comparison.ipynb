{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a637ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    mean_squared_error, mean_absolute_error, r2_score\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d96dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (5468, 45)\n",
      "Columns: ['id', 'year', 'state_name', 'state_code', 'district_name', 'district_code', 'registration_circles', 'murder', 'atmpt_commit_murder', 'simple_hurt', 'grievous_hurt', 'acid_attack', 'atmpt_acid_attack', 'other_grievous_hurt', 'assault_on_adult_women', 'sexual_harassment', 'atmpt_disrobe', 'voyeurism', 'stalking', 'assault_of_children_pocso', 'inslt_women_modesty', 'missing_children_kidnpd', 'other_kidnp_abduc', 'kidnp_begging', 'kidnp_murder', 'kidnapping_for_ransom', 'kidnp_marriage', 'procur_minor_girls', 'kidnp_abduc_sec_365_to_369', 'rape_of_women', 'rape_of_children', 'atmpt_rape', 'rioting', 'robbery', 'dacoity_with_murder', 'dacoity', 'arson', 'criminal_intimidation', 'other_ipc_crimes', 'intimitate_humiliate', 'occupy_land_blngs_sts', 'prvnt_obstruct_usage_pub_passage', 'frc_leave_place_res_soc_boycott', 'other_offences', 'protection_of_civil_rights']\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset\n",
    "file_path = \"districtwise-crime-against-sts-2017-onwards.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(\"Columns:\", df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fc2e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_col = None\n",
    "for c in df.columns:\n",
    "    if 'year' in c:\n",
    "        year_col = c\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ab53dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if year_col:\n",
    "    df[year_col] = pd.to_numeric(df[year_col], errors='coerce')\n",
    "else:\n",
    "    print(\"âš ï¸ No 'Year' column found â€” creating a dummy year index.\")\n",
    "    df['year'] = np.arange(len(df))\n",
    "    year_col = 'year'\n",
    "\n",
    "df = df.dropna(how='all')\n",
    "\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "df['total_offenses'] = df[num_cols].sum(axis=1)\n",
    "\n",
    "district_col = None\n",
    "for c in df.columns:\n",
    "    if 'district' in c:\n",
    "        district_col = c\n",
    "        break\n",
    "\n",
    "if district_col:\n",
    "    df['prev_year_total'] = (\n",
    "        df.sort_values([district_col, year_col])\n",
    "        .groupby(district_col)['total_offenses']\n",
    "        .shift(1)\n",
    "    )\n",
    "else:\n",
    "    df['prev_year_total'] = df['total_offenses'].shift(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ef5a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fill NaN values\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "204256c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using features: ['year', 'prev_year_total', 'state_code']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "features = [year_col, 'prev_year_total']\n",
    "\n",
    "for c in df.columns:\n",
    "    if 'state' in c and 'code' in c:\n",
    "        features.append(c)\n",
    "        break\n",
    "\n",
    "print(\"Using features:\", features)\n",
    "\n",
    "X = df[features]\n",
    "y_reg = df['total_offenses']\n",
    "y_clf = (df['total_offenses'] > df['total_offenses'].median()).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e71a80fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train_reg, y_test_reg, y_train_clf, y_test_clf = train_test_split(\n",
    "    X, y_reg, y_clf, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517cc8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Classification Models\n",
    "clf_models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Random Forest Classifier': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "clf_results = {}\n",
    "for name, model in clf_models.items():\n",
    "    model.fit(X_train, y_train_clf)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
    "\n",
    "    clf_results[name] = {\n",
    "        'Accuracy': accuracy_score(y_test_clf, y_pred),\n",
    "        'Precision': precision_score(y_test_clf, y_pred),\n",
    "        'Recall': recall_score(y_test_clf, y_pred),\n",
    "        'F1': f1_score(y_test_clf, y_pred),\n",
    "        'ROC_AUC': roc_auc_score(y_test_clf, y_prob)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f5b211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Regression Models\n",
    "reg_models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Random Forest Regressor': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "reg_results = {}\n",
    "for name, model in reg_models.items():\n",
    "    model.fit(X_train, y_train_reg)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    reg_results[name] = {\n",
    "        'MSE': mean_squared_error(y_test_reg, y_pred),\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_test_reg, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_test_reg, y_pred),\n",
    "        'RÂ²': r2_score(y_test_reg, y_pred)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43054f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š CLASSIFICATION RESULTS:\n",
      "\n",
      "Logistic Regression:\n",
      "  Accuracy: 0.8601\n",
      "  Precision: 0.8644\n",
      "  Recall: 0.8500\n",
      "  F1: 0.8571\n",
      "  ROC_AUC: 0.9040\n",
      "\n",
      "Random Forest Classifier:\n",
      "  Accuracy: 0.9662\n",
      "  Precision: 0.9736\n",
      "  Recall: 0.9574\n",
      "  F1: 0.9655\n",
      "  ROC_AUC: 0.9847\n",
      "\n",
      "ðŸ“ˆ REGRESSION RESULTS:\n",
      "\n",
      "Linear Regression:\n",
      "  MSE: 20354511.1280\n",
      "  RMSE: 4511.5974\n",
      "  MAE: 3046.7607\n",
      "  RÂ²: 0.4519\n",
      "\n",
      "Random Forest Regressor:\n",
      "  MSE: 8378823.7703\n",
      "  RMSE: 2894.6198\n",
      "  MAE: 1001.4580\n",
      "  RÂ²: 0.7744\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n CLASSIFICATION RESULTS:\")\n",
    "for model, metrics in clf_results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\n REGRESSION RESULTS:\")\n",
    "for model, metrics in reg_results.items():\n",
    "    print(f\"\\n{model}:\")\n",
    "    for metric, value in metrics.items():\n",
    "        print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "885bdf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comparing models\n",
    "best_clf = max(clf_results.items(), key=lambda x: x[1]['F1'])\n",
    "best_reg = max(reg_results.items(), key=lambda x: x[1]['RÂ²'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bff5e653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Classifier: Random Forest Classifier (F1: 0.965, ROC_AUC: 0.985)\n",
      "Best Regressor: Random Forest Regressor (RÂ²: 0.774, RMSE: 2894.620)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best Classifier: {best_clf[0]} (F1: {best_clf[1]['F1']:.3f}, ROC_AUC: {best_clf[1]['ROC_AUC']:.3f})\")\n",
    "print(f\"Best Regressor: {best_reg[0]} (RÂ²: {best_reg[1]['RÂ²']:.3f}, RMSE: {best_reg[1]['RMSE']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b83bd3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747bb0f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a40bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
